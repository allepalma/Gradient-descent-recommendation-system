{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UV decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data parsing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the data and retrieve the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Data Frame containing the ratings.\n",
    "data = np.genfromtxt('./ratings.dat',\n",
    "                     delimiter='::', usecols = (0, 1, 2), dtype = int)\n",
    "\n",
    "#Convert to a data frame and rename the columns\n",
    "ratings = pd.DataFrame(data)\n",
    "ratings.columns = ['user', 'movie', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the training userxmovie matrix\n",
    "rating_mat = ratings.pivot(index='user', columns='movie', values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will work with numpy arrays since faster. \n",
    "ratings_np = np.matrix(ratings)\n",
    "rating_mat_np = np.array(rating_mat)\n",
    "\n",
    "#ratings_np represents the data frame of ratings with information encoded as <userID, moviesID, rating>. \n",
    "#rating_mat_np is the sparse matrix of ratings we use for the optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the UV decomposition algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UV matrix decomposition algorithm aims to decompose a matrix $X$ to two lower rank matrices $U$ and $M$ such that their dot product represents a good approximation of $X$. This method can be adopted for the development of a recommendation system that approximates the utility matrix $X$ as the matrix product between a user matrix $U$ and an item matrix $M$. The principle behind the optimization algorithm lies in the subsequent substitution of all elements of the matrices $U$ and $M$ with variables to optimize one at the time. Upon encoding  one element of the two matrices with an independent variable, the square error between the utility matrix $X$ and the product $UM$ is subject to quadratic optimization. As we find the optimal value of one variable representing one element of either $U$ or $M$, we pass to the next entry to optimize of the same matrix. \n",
    "\n",
    "We will therefore optimize subsequently all elements of $U$ and then all elements of $M$. Performing a single traversal will although not be enough for the optimization to be fulfilled. Indeed, when a value is optimized, this means that previously already optimized values could be further improved by means of subsequent cycles of the algorithm, which prompts us to carry on with the same logic until a final convergence is met. In practice, we let the algorithm cycle for approximately 40 runs and evaluate its performance in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(ratings, n_users, n_movies, K):\n",
    "    '''\n",
    "    Given a rating data frame \"ratings\", the number of users and the number of movies and a constant K, the algorithm \n",
    "    initializes two matrices U and M of dimensions n_users*K and K*n_movies\n",
    "    '''\n",
    "    nan_mean = np.mean(ratings['rating'])\n",
    "    initialize = np.sqrt(nan_mean/K)\n",
    "    U = (np.repeat(initialize, K*n_users) + np.random.normal(0,1,K*n_users)).reshape((n_users, K))\n",
    "    M = (np.repeat(initialize, K*n_movies) + np.random.normal(0,1,K*n_movies)).reshape((K, n_movies))\n",
    "    return U,M\n",
    "\n",
    "def RMSE(ratings, X, P):\n",
    "    '''\n",
    "    RMSE computes the root mean squared error of two matrices, X and P. Ratings is an array containing the list of\n",
    "    ratings recorded as <userID, itemID, rating>.\n",
    "    '''\n",
    "    diff = X - P\n",
    "    n_non_missing = len(ratings) #The number of rows of the rating data frame is equivalent to the number of ratings we have\n",
    "    rmse = np.sqrt(np.nansum(diff**2)/n_non_missing)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def UV_decomp(ratings, X, U, M, K = 10, iter = 40):\n",
    "    '''\n",
    "    Implement the UV matrix decomposition algorithm.\n",
    "    '''\n",
    "    res = []\n",
    "    #Fix the old and new RMSE values.\n",
    "    RMSE_old = 1000\n",
    "    RMSE_new = RMSE(ratings, X, U.dot(M))\n",
    "    #cols_X and rows_X simply contain the indexes of the rows and columns of the\n",
    "    #matrix X. They will be used for cycling.\n",
    "    cols_X = np.arange(np.size(X,1))\n",
    "    rows_X = np.arange(np.size(X,0))\n",
    "    #Features is a vector from 0 to K-1.\n",
    "    features = np.arange(K)\n",
    "    count = 1\n",
    "    while count<=iter:\n",
    "        RMSE_old = RMSE_new\n",
    "        #Cycle across the rows and columns of U. \n",
    "        for r in rows_X:\n",
    "            #To implement update formulas you need to get the columns\n",
    "            #of X such that their value at the row r is not NaN. \n",
    "            non_missing_cols = cols_X[~ np.isnan(list(X[r,:]))]\n",
    "            for s in features:               \n",
    "                num = np.sum(M[s, non_missing_cols] * (X[r, non_missing_cols] - \n",
    "                        U[r,np.delete(features, s)].dot(M[np.delete(features, s)][:,non_missing_cols])))\n",
    "                den = np.sum(M[s,non_missing_cols]**2)\n",
    "                U[r,s] = num/den\n",
    "        #Repeat the process to update M\n",
    "        for s in cols_X: \n",
    "            non_missing_rows = rows_X[~ np.isnan(list(X[:, s]))]\n",
    "            for r in features:   \n",
    "                num = np.sum(U[non_missing_rows, r] * (X[non_missing_rows, s] - \n",
    "                    U[non_missing_rows][:,np.delete(features, r)].dot(M[np.delete(features, r),s])))\n",
    "                den = np.sum(U[non_missing_rows, r]**2)\n",
    "                M[r,s] = num/den\n",
    "        #Compute the matrix product between the new U and M.\n",
    "        RMSE_new = RMSE(ratings, X , U.dot(M))\n",
    "        res.append(RMSE_new)\n",
    "        count += 1 \n",
    "    return U.dot(M), res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test by cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation function\n",
    "def cv(ratings, K, iter):\n",
    "    #Set a seed for reproducibility\n",
    "    np.random.seed(888)\n",
    "\n",
    "    #Generate the 5 folds for all rows of the utility matrix of input.\n",
    "    nfolds = 5\n",
    "    folds = np.array([x%nfolds for x in range(len(ratings))])\n",
    "    np.random.shuffle(folds)\n",
    "\n",
    "    #Set up the vectors of errors. \n",
    "    errors_5folds_rmse_training = []\n",
    "    errors_5folds_rmse_test = [] \n",
    "\n",
    "    '''\n",
    "    We will cycle through the possible folds (from 1 to 5) and leave one set of observations (test set) out of the training process.\n",
    "    Then, we use it to perform predictions and compute the error. \n",
    "    '''\n",
    "    \n",
    "    for i in range(5):\n",
    "        print('Fold {0}'.format(i))\n",
    "        #Fix the rows of the ratings Data Frame that will be the training set.\n",
    "        train = ratings.loc[folds!=i, :]\n",
    "        train_mat = train.pivot(index='user', columns='movie', values='rating')\n",
    "        train_np = np.matrix(train)\n",
    "        train_mat_np = np.array(train_mat)\n",
    "    \n",
    "        #Create lookup dictionary associating the indices of the numpy array to the\n",
    "        #respective movieID and userID.\n",
    "        col_names_train = {train_mat.columns[j]:j for j in range(len(train_mat.columns))}\n",
    "        row_names_train_ = {train_mat.index[j]:j for j in range(len(train_mat.index))}   \n",
    "    \n",
    "        #Initialize U and M and run the prediction.\n",
    "        U, M = initialize(train, np.size(train_mat_np,0), np.size(train_mat_np,1), K)\n",
    "        pred, res = UV_decomp(train_np, train_mat_np, U, M, K = K, iter = iter)\n",
    "    \n",
    "        #Initialize test set\n",
    "        test =  ratings.loc[folds == i, :]\n",
    "        test_np = np.matrix(test)\n",
    "        test_pred = []\n",
    "    \n",
    "        #The global mean of the training matrix will be used as a prediction for the observations that have a missing \n",
    "        #movie or user in the training set.\n",
    "        global_mean = np.mean(train['rating'])\n",
    "    \n",
    "        #Create the prediction vector of the test set. If a user or item are not present\n",
    "        #in the training set, predict their rating as the gloal mean of the training matrix.\n",
    "        for val in test_np:\n",
    "            if val[0,0] in row_names_train and val[0,1] in col_names_train:\n",
    "                test_pred.append(pred[row_names_train[val[0,0]], col_names_train[val[0,1]]])\n",
    "            else:\n",
    "                test_pred.append(global_mean)\n",
    "       \n",
    "        test_pred = np.array(test_pred)\n",
    "        test_obs = np.array(test['rating'])\n",
    "    \n",
    "    \n",
    "        #Extra fallback rules to improve performance. We round to 1 all predictions lower than 1 and to 5 all prediction higher \n",
    "        #than 5\n",
    "        test_pred = np.where(test_pred > 5, 5, test_pred)\n",
    "        test_pred = np.where(test_pred < 1, 1, test_pred)\n",
    "    \n",
    "        #Calculate and store the errors on the training set and test set. \n",
    "        errors_5folds_rmse_training.append(RMSE(train_np,train_mat_np, pred))\n",
    "    \n",
    "        #Calculate the error on the test set and store it.\n",
    "        test_RMSE = np.sqrt(np.sum((test_pred-test_obs)**2)/len(test_pred)) \n",
    "        errors_5folds_rmse_test.append(test_RMSE)\n",
    "        \n",
    "       \n",
    "    \n",
    "        partial_error.append(res)    \n",
    "\n",
    "    #Average across the folds to compute the errors. \n",
    "    cv_error_rmse_train = np.mean(errors_5folds_rmse_training)\n",
    "    cv_error_rmse_test = np.mean(errors_5folds_rmse_test)\n",
    "\n",
    "    print('The average rmse over the training set for iter = ',iter,' and K = ',K,' is: ', cv_error_rmse_train)\n",
    "    print('The average rmse over the test set for iter = ',iter,' and K = ',K,' is: ', cv_error_rmse_test)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To call cross-validation function, use:\n",
    "#cv(ratings, value of K, number of iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
